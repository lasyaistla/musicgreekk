{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "polygansipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOiCXfy/7Ua3SMFaELAu5/Y",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lasyaistla/musicgreekk/blob/main/polygansipynb.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 341
        },
        "id": "Gl9zrXX8sKEr",
        "outputId": "e8c99492-70c3-4dde-d5d9-0641c46861b3"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-a67eab2e92f8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[0;31m# Load appropriate input data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m     \u001b[0minput_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_from_folder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubsample\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m400\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    148\u001b[0m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_images\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0minput_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdisplay_window\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-3-a67eab2e92f8>\u001b[0m in \u001b[0;36mload_from_folder\u001b[0;34m(folder_name, subsample)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;31m# Laoding healthy image dataset from folder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mload_from_folder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfolder_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubsample\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m     \u001b[0mimg_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mf\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfolder_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mimg_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mimg_names\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: ''"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Reshape\n",
        "from keras.layers.core import Activation\n",
        "from keras.layers.convolutional import UpSampling2D\n",
        "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
        "from keras.layers.core import Flatten\n",
        "import numpy as np\n",
        "import math\n",
        "import cv2\n",
        "import keras.backend as K\n",
        "\n",
        "# Defining image properties\n",
        "input_dims = 100  # Number of random inputs per generated image.\n",
        "img_side = 100  #length of the image in pixels\n",
        "n_color_channels = 1  # Number of color channels: 3 for colored images (like cifar) and 1 for grayscale (like mnist).\n",
        "batch_size = 20  # Number of images per batch.\n",
        "epochs = 300  # Number of training epochs.\n",
        "\n",
        "\n",
        "# Laoding healthy image dataset from folder\n",
        "def load_from_folder(folder_name=\"\", subsample=2000):\n",
        "    img_names = [f for f in os.listdir(folder_name) if not f.startswith('.')]\n",
        "    x = []\n",
        "    for img_name in img_names:\n",
        "        im = cv2.imread(folder_name+\"/\" + img_name, cv2.IMREAD_GRAYSCALE)\n",
        "        x.append(im)\n",
        "\n",
        "    x = np.asarray(x)\n",
        "    x = x.reshape(x.shape[0],x.shape[1],x.shape[2],1)\n",
        "    print(x.shape)\n",
        "    return x[:subsample]\n",
        "\n",
        "\n",
        "#defining generator\n",
        "def generator():\n",
        "    model = Sequential()\n",
        "    model.add(Dense(1024, input_dim=input_dims, activation=\"tanh\"))\n",
        "    model.add(Dense(64 * (img_side // 4) * (img_side // 4)))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Activation('tanh'))\n",
        "    model.add(Reshape((img_side // 4, img_side // 4, 64), input_shape=(64 * (img_side // 4) * (img_side // 4,))))\n",
        "    model.add(UpSampling2D(size=(2, 2)))\n",
        "    model.add(Conv2D(32, (5, 5), padding=\"same\"))\n",
        "    model.add(Activation('tanh'))\n",
        "    model.add(UpSampling2D(size=(2, 2)))\n",
        "    model.add(Conv2D(n_color_channels, (5, 5), padding='same'))\n",
        "    model.add(Activation('tanh'))\n",
        "    return model\n",
        "\n",
        "\n",
        "# Defining Discriminator\n",
        "def discriminator():\n",
        "    model = Sequential()\n",
        "    model.add(Conv2D(32, (5, 5), padding='same', input_shape=(img_side, img_side, n_color_channels)))\n",
        "    model.add(Activation('tanh'))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "    model.add(Conv2D(64, (5, 5)))\n",
        "    model.add(Activation('tanh'))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(1024))\n",
        "    model.add(Activation('tanh'))\n",
        "    model.add(Dense(1))\n",
        "    model.add(Activation('sigmoid'))\n",
        "    return model\n",
        "\n",
        "# Generating GAN by combining Discriminator and Generator\n",
        "def GAN(gen, discrim):\n",
        "    model = Sequential()\n",
        "    model.add(gen)\n",
        "    discrim.trainable = False\n",
        "    model.add(discrim)\n",
        "    return model\n",
        "\n",
        "# combining generated images to display\n",
        "def combine_images(gen_images):\n",
        "    num = gen_images.shape[0]\n",
        "    width = int(math.sqrt(num))\n",
        "    height = int(math.ceil(float(num) / width))\n",
        "    shape = gen_images.shape[1:]\n",
        "    image = np.zeros((height * shape[0], width * shape[1], shape[2]),\n",
        "                     dtype=gen_images.dtype)\n",
        "    for index, img in enumerate(gen_images):\n",
        "        i = int(index / width)\n",
        "        j = index % width\n",
        "        image[i * shape[0]:(i + 1) * shape[0], j * shape[1]:(j + 1) * shape[1]] = img[:, :, :]\n",
        "    return image\n",
        "\n",
        "# Defining Training and plotting process\n",
        "def train(training_images, batch_size=16, epochs=10, display_window=2):\n",
        "    X_train = training_images\n",
        "\n",
        "    X_train = (X_train.astype(np.float32) - 127.5) / 127.5  # Convert from range (0 to 255) to range (-1 to 1)\n",
        "\n",
        "    d = discriminator()\n",
        "    g = generator()\n",
        "    gan = GAN(g, d)\n",
        "    d_optim = SGD()    # TODO: Try new optimizers. SGD is kinda shitty but fast.\n",
        "    g_optim = SGD()\n",
        "    gan.compile(loss=\"binary_crossentropy\", optimizer=g_optim)\n",
        "    d.trainable = True\n",
        "    d.compile(loss=\"binary_crossentropy\", optimizer=d_optim)\n",
        "    for epoch in range(1, epochs + 1):\n",
        "        print(\"Epoch is \", epoch)\n",
        "        # print(\"Number of batches\", int(X_train.shape[0] / batch_size))\n",
        "        for index in range(X_train.shape[0] // batch_size):\n",
        "            noise = np.random.uniform(-1, 1, size=(batch_size, input_dims))\n",
        "            image_batch = X_train[index * batch_size: (index + 1) * batch_size]\n",
        "            generated_images = g.predict(noise, verbose=0)\n",
        "\n",
        "            if index % display_window == 0:\n",
        "                # Stitch images into one image\n",
        "                image = combine_images(generated_images)\n",
        "                original = combine_images(image_batch)\n",
        "\n",
        "                # Convert pixel intensity back to range (0-255) and cast to int\n",
        "                image = (image * 127.5 + 127.5).astype(np.uint8)\n",
        "                original = (original * 127.5 + 127.5).astype(np.uint8)\n",
        "\n",
        "                zoomfactor = 2  # Zooming levels during display\n",
        "\n",
        "                image = cv2.resize(image, (image.shape[0] * zoomfactor, image.shape[0] * zoomfactor))\n",
        "                original = cv2.resize(original, (original.shape[0] * zoomfactor, original.shape[0] * zoomfactor))\n",
        "                cv2.imshow('Output', image)\n",
        "                cv2.imshow('Input', original)\n",
        "                cv2.waitKey(1)\n",
        "\n",
        "            # print(image_batch.shape, generated_images.shape)\n",
        "            X = np.concatenate((image_batch, generated_images))\n",
        "            y = [1] * batch_size + [0] * batch_size\n",
        "            d_loss = d.train_on_batch(X, y)\n",
        "            noise = np.random.uniform(-1, 1, size=(batch_size, input_dims))\n",
        "            d.trainable = False\n",
        "            g_loss = gan.train_on_batch(noise, [1] * batch_size)\n",
        "            d.trainable = True\n",
        "\n",
        "            # Saving images at the given interval\n",
        "            if epoch % display_window == 0:\n",
        "                cv2.imwrite('D:\\kavya\\code\\outputs\\image' + str(epoch) + \".png\", image)\n",
        "\n",
        "\n",
        "# Load appropriate input data\n",
        "if __name__ == '__main__':\n",
        "    input_data = load_from_folder(subsample=400)\n",
        "    train(training_images= input_data,batch_size=batch_size, epochs=epochs, display_window=10)"
      ]
    }
  ]
}